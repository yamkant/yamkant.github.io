---
layout: archive
title:  "[Server] Docker network를 통한 Nginx와 django server 세팅"
date:   2023-05-12 16:05:07 +0900
categories: [Server]
---

## 글을 작성하게 된 계기
- docker compose 내에 nginx / django server / db를 모두 넣는 방식은 network를 서로 공유할 수 있다는 편리함을 가졌지만 서로 독립적으로 컨트롤 할 수 없다는 단점을 가지고 있습니다.
- server 증설 및 감축을 위해 설정을 간소화하는 방법을 모색 중에, docker network를 활용하는 방법을 생각해보며 글을 작성하게 되었습니다.

### 최종 목표
- nginx 단독 컨테이너 구성
- docker-compose를 사용한 django server 여러대 구성
- nginx load balancing을 활용한 django server 구동
- Blue-Green 배포 형식으로 nginx 및 docker-compose 세팅

**순서**
1. custom network 생성
2. nginx 단독 container 구성
3. django server 구성(docker-compose로 구성 x custom network)
4. custom network 연결 (nginx container 실행 및 custom network)
5. nginx 배포환경 구성 (django server들과 reverse proxy를 통한 load balancing 환경 구성)

## 1. Custom network 생성
참고: https://itbhome.tistory.com/47

```shell
# custom network를 원하는 대역에 생성
$ docker network create \
    --driver=bridge \
    --subnet=172.20.0.0/16 \
    --gateway=172.20.0.1 \
    my-network
```

## 2. nginx 단독 container 구성
**nginx 설정파일**
```nginx
# templates/default.conf.template

server {
    listen       80;
    server_name  80;

    access_log  /var/log/nginx/logs/host.access.log  main;
    error_log   /var/log/nginx/logs/host.error.log crit;

    location / {
        return 308 https://$host$request_uri;
    }
    ...
}

#// upstream servers {
#//     server server1:8000;
#//     server server2:8000;
#// }

#HTTPS server
server {
    listen       443 ssl http2;
    ssl_certificate /etc/letsencrypt/live/${NGINX_HOST}/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/${NGINX_HOST}/privkey.pem;        

    access_log  /var/log/nginx/logs/host.access.log  main;
    error_log /var/log/nginx/logs/host.error.log crit;


    location / {
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        #// proxy_pass http://servers;
    }
}
```
- 환경변수를 활용하여 conf 파일을 변경하는 경우가 생길 수 있기 때문에, template 파일을 작성 후, nginx container 내부 sh 파일을 통해 이를 치환합니다. (위의 예제에서는 NGINX_HOST 변수처리)
- 해당 파일은 치환이 완료되면 `.template` 접미사가 제거되며 docker container 내부에서는 /etc/nginx/conf.d/default.conf로 변환됩니다. 
- `#//`로 처리해둔 주석은 이 후에, 서버 배포가 진행될 때 `conf.d/default.conf`를 수정하는 과정에서 지우게 될 주석입니다.

**Dockerfile 및 run.sh**
```docker
# Dockerfile

FROM nginx:1.21.6

RUN apt-get update
RUN apt-get install -y openssl

COPY ./code/nginx.conf /etc/nginx/nginx.conf
COPY ./code/run.sh /run.sh
COPY ./code/set_nginx_conf.sh /set_nginx_conf.sh
COPY ./code/templates /etc/nginx/templates

ENV NGINX_HOST localhost
ENV INITIAL_START 1

CMD ["/bin/bash", "/run.sh"]
```
```
# run.sh

#!/bin/bash

DIR_PEM="/etc/letsencrypt/live/$NGINX_HOST"
if [ -d "$DIR_PEM" ]; then
  echo "OPEN SSL SETTING DONE"
else
  echo "OPEN SSL SETTING DOING"
  mkdir -p /etc/letsencrypt/live/$NGINX_HOST
  ### Take action if $DIR exists ###
  openssl req -x509 -nodes -newkey rsa:4096 -days 1\
    -keyout "/etc/letsencrypt/live/$NGINX_HOST/privkey.pem" \
    -out "/etc/letsencrypt/live/$NGINX_HOST/fullchain.pem" \
    -subj "/CN=localhost"
fi

echo "환경변수 출력"
echo $INITIAL_START

# nginx 실행 전 템플릿 파일의 변수를 환경 변수 값으로 변경해주는 구문입니다.
if [ "$INITIAL_START" -eq '1' ]; then
  bash /docker-entrypoint.d/20-envsubst-on-templates.sh
  INITIAL_START="0"
fi
nginx -g "daemon off;"
```
- run.sh는 openssl 설정 및 환경변수 값으로 치환하기 위한 프로그램 수행, nginx를 실행하는 역할을 합니다.

**nginx container 실행 및 네트워크 연결**
```shell
# docker_run.sh

#!/bin/bash

CUR_PATH="$( cd "$( dirname "$0" )" && pwd -P )"
IMAGE_NAME=my-nginx:1.0
MOUNT_LOG_DIR=$CUR_PATH/code/logs
MOUNT_CONF_DIR=$CUR_PATH/code/conf.d

docker build -t $IMAGE_NAME $CUR_PATH
docker run -d -p 80:80 -p 443:443 -v $MOUNT_LOG_DIR:/var/log/nginx/logs -v $MOUNT_CONF_DIR:/etc/nginx/conf.d --name my-nginx $IMAGE_NAME

# connect custom network for nginx container 
docker network connect my-network my-nginx
```
- HOST에서도 nginx의 로그와 설정값을 관리하기 위해 컨테이너와 Volume을 연결하도록 설정합니다.

## 4. Django server 구성
```docker-compose
# docker-compose.yaml

version: '3'
services:
  server-blue-1:
    container_name: my-blue-server-1
    build: ./django_server
    networks:
      - my-network
    command: python manage.py runserver 0.0.0.0:8000
    env_file:
      - ./django_server/.env
    environment:
      - PROFILE=set1-server1
  server-blue-2:
    container_name: my-blue-server-2
    build: ./django_server
    networks:
      - my-network
    command: python manage.py runserver 0.0.0.0:8000
    env_file:
      - ./django_server/.env
    environment:
      - PROFILE=set1-server2
  # monitor:
  #   build: ./monitor_server
  #   command: tail -f /dev/null
  #   container_name: my-monitor

networks:
  my-network:
    name: my-network
    external: true
```
- server-blue-1, server-blue-2 등 같은 버전의 여러대의 컨테이너로 docker-compose를 구성합니다.
- 이미 생성된 custom network에 docker-compose를 연결합니다.
- 혹시(?) 사용하게 될지도 모르는 monitor 서버를 추가적으로 구성합니다.
- `docker compose up -d`를 통해 compose를 빌드할 수 있습니다. 

```docker-compose
docker-compose.green.yaml

version: '3'
services:
  server-green-1:
    container_name: my-green-server-1
    build: ./django_server
    networks:
      - my-network
    command: python manage.py runserver 0.0.0.0:8000
    env_file:
      - ./django_server/.env
    environment:
      - PROFILE=set2-server1
  server-green-2:
    container_name: my-green-server-2
    build: ./django_server
    networks:
      - my-network
    command: python manage.py runserver 0.0.0.0:8000
    env_file:
      - ./django_server/.env
    environment:
      - PROFILE=set2-server2
  # monitor:
  #   build: ./monitor_server
  #   command: tail -f /dev/null
  #   container_name: my-monitor

networks:
  my-network:
    name: my-network
    external: true
```
- server-green-1, server-green-2 등 새로운 버전을 위한 compose 파일을 구성합니다.
- `docker compose -f docker-compose.green.yaml up -d`를 통해 compose를 빌드할 수 있습니다. 

### 확인
```shell
$ docker network inspect my-network
[
    {
        "Name": "my-network",
        ...
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.20.0.0/16",
                    "Gateway": "172.20.0.1"
                }
            ]
        },
        ...
        "Containers": {
            "04d6e1ec538cb14cec01a3409fae0a455921e04af484ebb8769903a6fec3d512": {
                "Name": "my-blue-server-1",
                "EndpointID": "38ccfbc39486e2d93526bb6e783e360cd7d7df70830bdfbab026ee55d8f75bb7",
                "MacAddress": "02:42:ac:14:00:04",
                "IPv4Address": "172.20.0.4/16",
                "IPv6Address": ""
            },
            "8ceb50dbe27da8186713140224f32c47467f37779ead0dea8ecb692ae178446d": {
                "Name": "my-blue-server-2",
                "EndpointID": "2b5fe995ab6333f4cef560fabc18d83c5e1289239532489c25a46d1d1d03245b",
                "MacAddress": "02:42:ac:14:00:03",
                "IPv4Address": "172.20.0.3/16",
                "IPv6Address": ""
            },
            "07f74941d4bdc431eea721ff82c6e14f920fa3a9940abd12a087147f210e8770": {
                "Name": "my-green-server-1",
                "EndpointID": "af7765925d505e8c066741e7fc596632c1c91633cc6d2d9b25bca3abe2c7268a",
                "MacAddress": "02:42:ac:14:00:05",
                "IPv4Address": "172.20.0.5/16",
                "IPv6Address": ""
            },
            "d8c439c7373e516b3135916cbc018e1e4f8126517257eb1c252b169a94ec5688": {
                "Name": "my-green-server-2",
                "EndpointID": "250870e9bd90e0335663134d373eac140dbf1268ac95be1ee333df21bd555f63",
                "MacAddress": "02:42:ac:14:00:06",
                "IPv4Address": "172.20.0.6/16",
                "IPv6Address": ""
            }
            "bd8ed048dc19c8fd438453793e63642ee631a935fa3487a46a6408a1ea4af5e7": {
                "Name": "my-nginx",
                "EndpointID": "25f3dc806ac591f49595e6fe349562b6d744b46fdd935e67343659d5b8f8ff2e",
                "MacAddress": "02:42:ac:14:00:02",
                "IPv4Address": "172.20.0.2/16",
                "IPv6Address": ""
            },
        },
        ...
    }
]
```
- 위 과정들을 전부 수행하면 my-nginx, blue server들, green server들이 gateway에 배치되어, 서로 ping, curl 등 network tool을 통해 소통할 수 있게 됩니다.

## 5. Nginx 배포환경 구성
```shell
# set_nginx_conf.sh

#!/bin/bash

SRC_SERVER1=$1
SRC_SERVER2=$2
TAR_SERVER1=$3
TAR_SERVER2=$4

# Firstly, remove the comment keywords
sed -i 's|#// ||g' /etc/nginx/conf.d/default.conf
# Secondly, set nginx upstream hostname
sed -i "s|${SRC_SERVER1}|${TAR_SERVER1}|g" /etc/nginx/conf.d/default.conf
sed -i "s|${SRC_SERVER2}|${TAR_SERVER2}|g" /etc/nginx/conf.d/default.conf
```
- 2번 단계에서 설정했던 nginx 설정 파일을 수정하여 배포 환경에 맞게 수정하는 파일로, upstream 부분의 reverse proxy 부분을 수정합니다.
- 기존에 server1, server2로 되어있던 부분을 `my-network`(위에서 커스텀으로 설정한)에서 받아와서 설정해야합니다. (아래 `deploy.sh` 참고)

```shell
# deploy.sh

---

#!/bin/bash
PARAM=${1:?"requires an argument. in: init, dp: deploy, rb: rollback"}

BLUE_SERVER_1_HOST=`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' my-blue-server-1`
BLUE_SERVER_2_HOST=`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' my-blue-server-2`
GREEN_SERVER_1_HOST=`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' my-green-server-1`
GREEN_SERVER_2_HOST=`docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' my-green-server-2`

if [ -z "$GREEN_SERVER_1_HOST" -o  -z "$GREEN_SERVER_2_HOST" ]; then
  if [ $PARAM != 'in' ]; then
    echo "Turn on green servers first."
    exit
  fi
fi
 
if [ $PARAM == 'in' ]; then
  docker exec -it my-nginx /set_nginx_conf.sh server1 server2 $BLUE_SERVER_1_HOST $BLUE_SERVER_2_HOST
elif [ $PARAM == 'rb' ]; then
  docker exec -it my-nginx /set_nginx_conf.sh $GREEN_SERVER_1_HOST $GREEN_SERVER_2_HOST $BLUE_SERVER_1_HOST $BLUE_SERVER_2_HOST
else
  docker exec -it my-nginx /set_nginx_conf.sh $BLUE_SERVER_1_HOST $BLUE_SERVER_2_HOST $GREEN_SERVER_1_HOST $GREEN_SERVER_2_HOST
fi

# nginx reload in docker
docker exec -it my-nginx nginx -s reload
```
- in: initial 모드로, nginx.conf의 server1, server2를 my-network에서 컨테이너명에 따라 가져온 IP로 변경합니다. (my-blue-server1, my-blue-server2가 될 것)
- dp: 새로운 버전을 배포하는 모드로, blue-server1, blue-server2에 연결되어 있던 reverse proxy를 green-server1, green-server2로 연결되도록 수정합니다.
- rb: 롤백 모드로, green-server1, green-server2로 연결되어 있던 reverse proxy를 blue-server1, blue-server2로 연결되도록 다시 수정합니다.
- in 모드가 아니고 green server가 배포가 되어있지 않다면, 배포 프로세스를 진행하지 않습니다.

## 배포 순서
- 최종 디렉토리 레벨은 다음과 같습니다.  

    ```
    - /root
      - nginx/
        - templates/
            - default.conf.template
        - code/
            - nginx.conf
            - run.sh
            - set_nginx_conf.sh
            - Dockerfile
        - docker_run.sh

      - server/
        - django_server/
            - Dockerfile
            - ...
        - monitor_server/
            - Dockerfile
            - ...
        - docker-compose.yaml
        - docker-compose.green.yaml

      - create_network.sh
    ```

**초기 컨테이너들 설정**  
- 아래 명령어들은 root 폴더에서 진행합니다.
1. 새로운 network 생성: `./create_network.sh`   
2. server 실행:  `docker-compose -f ./server/docker-compose.yaml up -d`  
3. nginx 실행 및 새로운 network 연결: `nginx/docker_ruh.sh`
4. 초기 배포 수행: `./deploy.sh in`  

**새로운 배포를 하는 경우**  
5. server 실행: `docker-compose -f ./server/docker-compose.green.yaml up -d`
6. 새로운 배포 수행: `./deploy.sh dp`  

**롤백하는 경우**  
7. 롤백 후 재배포 수행: `./deploy.sh rb`